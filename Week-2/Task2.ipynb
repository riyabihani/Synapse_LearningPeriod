{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.12"},"colab":{"name":"Task2.ipynb","provenance":[],"collapsed_sections":["niwpNf_EYNC9","TvhXRmGyYNC_","ZBLwVsQIYNDA","a7pxLfloYNDM","QPOM6rXpYNDW","LDYWYnvwYNDY","OIFaYgUWYNDa","vWiXgySxYNDd","N6tS1j4iYNDe"]}},"cells":[{"cell_type":"markdown","metadata":{"id":"2GKIJx3sYNC0"},"source":["# Task 2\n","This week you have learnt about various types of ML models. <br>\n","Let us focus on two of them."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PQ4lXvV6YW_5","executionInfo":{"status":"ok","timestamp":1633352328429,"user_tz":-330,"elapsed":26072,"user":{"displayName":"Amay Gada","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIegWflm0DVHy8h-sj9l7nvh_87WZPEby6oqxqjw=s64","userId":"18318224108445437394"}},"outputId":"7b8f8554-2f9e-4a73-b378-dc3f2986812f"},"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"markdown","metadata":{"id":"fKEbTpqVYg8m"},"source":["# Instructions\n","1. create a folder called synapse_w2 in your drive\n","2. add housing_data.csv, classified_data.txt, titanic_data.csv in the folder.\n","3. You will use the data from this path in this notebook"]},{"cell_type":"code","metadata":{"id":"88aLM-5hYgVL"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yJqOW8lFYNC3"},"source":["# 1)  Linear Regression on Housing Price"]},{"cell_type":"markdown","metadata":{"id":"hZGyek2wYNC4"},"source":["### Import packages and dataset"]},{"cell_type":"code","metadata":{"id":"C--rF9aZYNC4"},"source":["# import numpy, pandas, matplotlib, seaborn\n","# add code here\n","\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P8Kgu-VJYNC5"},"source":["**Read housing_data.csv using pandas and call head() to show first few records.**"]},{"cell_type":"code","metadata":{"id":"qrdEbQKxYNC5"},"source":["# add code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_158HqRTYNC6"},"source":["### Exloratory Data Analysis (EDA)"]},{"cell_type":"markdown","metadata":{"id":"YbmnOZ48YNC6"},"source":["**'info()' method to check the data types and number**"]},{"cell_type":"code","metadata":{"id":"7YWr6trZYNC6"},"source":["# add code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-XVB-HteYNC7"},"source":["**Get the statistical summary of the data set** <br>\n","Hint: describe()"]},{"cell_type":"code","metadata":{"id":"XZPbIjgYYNC7"},"source":["# add code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DfSgsewYYNC7"},"source":["**Print the names of the columns(features)**"]},{"cell_type":"code","metadata":{"id":"9ss5VF20YNC8"},"source":["# add code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p0HiN5NeYNC8"},"source":["### Basic plotting and visualization"]},{"cell_type":"markdown","metadata":{"id":"-rumpxTXYNC8"},"source":["**The target quantity is price. Let us see its distribution.** <br>\n","Plot a histogram of Price. Choose the number of bins by experimenting a little. (Expected: a bell curve shape)"]},{"cell_type":"code","metadata":{"id":"8BGkFMVBYNC8"},"source":["# add code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Al174yCyYNC9"},"source":["**Let us see how the different features are correlated with each other by printing a Correlation Matrix**<br>\n","Hint: corr()"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"aaLwISKZYNC9"},"source":["# add code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"niwpNf_EYNC9"},"source":["### Feature and variable sets"]},{"cell_type":"markdown","metadata":{"id":"YZRq4NakYNC9"},"source":["**Make a list of data frame column names**\n","**Create a new dataframe containing all the numerical training features(note that Address is a string so ignore that) and store it in a variable called \"X\"**<br><br>\n","**Then create a new dataframe containing the target (Price) and store it in a variable called \"y\"**"]},{"cell_type":"code","metadata":{"id":"KBKubTuLYNC-"},"source":["# add code here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2w-pU7UhYNC-"},"source":["# This code should print (5000, 5) and (5000,) if everything is correct\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qC6JzmuDYNC-"},"source":["# print a few record of X\n","# add code here\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rQ9RkZ1-YNC-"},"source":["# print a few record of y\n","# add code here\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TvhXRmGyYNC_"},"source":["### Test-train split"]},{"cell_type":"markdown","metadata":{"id":"A-I6E4XuYNC_"},"source":["**Import train_test_split function from scikit-learn**"]},{"cell_type":"code","metadata":{"id":"SJ2t9WC4YNC_"},"source":["# add code here\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wTHAGB7pYNC_"},"source":["**Create X and y train and test splits in one command using a test size of 0.3 and a random seed**<br>\n","They should be called X_train, X_test, y_train, y_test"]},{"cell_type":"code","metadata":{"id":"gZWMHfPcYNC_"},"source":["# add code here\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xyfldBi7YNDA"},"source":["**Print the size and shape of each of the train/test splits (it should be in the ratio as per test_size parameter above)**"]},{"cell_type":"code","metadata":{"id":"PTMhv-xlYNDA"},"source":["# add code here\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZBLwVsQIYNDA"},"source":["### Model fit and training"]},{"cell_type":"markdown","metadata":{"id":"uNPr5Xb0YNDA"},"source":["**Import LinearRegression and metrics from scikit-learn**"]},{"cell_type":"code","metadata":{"id":"llBzX5-EYNDA"},"source":["# add code for imports here\n","\n","# Create a Linear Regression object 'lm' by calling LinearRegression()\n","# add code here\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rRzoOJXhYNDA"},"source":["**Fit the model on to the instantiated object itself using the X_train and y_train created earlier. No need to create another variable**<br>\n","Hint: lm.fit()"]},{"cell_type":"code","metadata":{"id":"R9U1pME1YNDB"},"source":["# add code here\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a7pxLfloYNDM"},"source":["### Prediction, error estimate, and regression evaluation matrices"]},{"cell_type":"markdown","metadata":{"id":"rOXcTK_iYNDN"},"source":["**Prediction using the lm model**<br>\n","Use model.predict() on X_test and store them in a variable called \"predictions\".<br>\n","Print type and size of the predictions. Size should be (1500,) if everything is correct."]},{"cell_type":"code","metadata":{"id":"ef28Cy7pYNDP"},"source":["# add code here\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rPM6_2M5YNDQ"},"source":["**Since we're done with our predictions, let's compare it with y_test and see how accurate our predictions are.<br> Plot a Scatter plot of predicted price and y_test set to see if the data fall on a 45 degree straight line**"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"2T7YcpWMYNDQ"},"source":["# add code here\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LZtFB738YNDS"},"source":["**Print the R-square value and round it to 3 decimal places**<br>\n","Hint: sklearn metrics.r2_score"]},{"cell_type":"code","metadata":{"id":"IGKgAkCDYNDS"},"source":["# add code here\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2jroGWezYNDT"},"source":["# 2) K-nearest neighbor Classification"]},{"cell_type":"markdown","metadata":{"id":"WHlWn6YXYNDU"},"source":["### Import packages and dataset"]},{"cell_type":"code","metadata":{"id":"xJAjpGbYYNDU"},"source":["# import numpy, pandas, matplotlib, seaborn\n","# add code here\n","\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8RWyQOGrYNDV"},"source":["**Read classified_data.txt using pandas and call head() to show first few records. Call this dataframe \"df\"** <br>\n","Use \"index_col\" parameter to index the dataframe according to the first column. Otherwise, a new column would get created."]},{"cell_type":"code","metadata":{"id":"0GDXB_9GYNDV"},"source":["# add code here\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QPOM6rXpYNDW"},"source":["### Exloratory Data Analysis (EDA)"]},{"cell_type":"markdown","metadata":{"id":"2J-RhwE5YNDW"},"source":["**'info()' method to check the data types and number**"]},{"cell_type":"code","metadata":{"id":"LQ27teSgYNDW"},"source":["# add code here\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lwSF-PxbYNDX"},"source":["**Get the statistical summary of the data set** <br>\n","Hint: describe()"]},{"cell_type":"code","metadata":{"id":"g7XvMQ5eYNDX"},"source":["# add code here\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LDYWYnvwYNDY"},"source":["### Check the spread of the features"]},{"cell_type":"markdown","metadata":{"id":"Q0hgD8wlYNDY"},"source":["**Store the column names in a list**"]},{"cell_type":"code","metadata":{"id":"rxAYeNSzYNDY"},"source":["# add code here\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N3g0ISUGYNDZ"},"source":["**Run a 'for' loop to draw boxplots of all the features for '0' and '1' TARGET CLASS**<br>\n","Hint: Loop through each of the 10 features and draw a separate boxplot. You should have 10 boxplots in total. <br>\n","Refer seaborn boxplot() "]},{"cell_type":"code","metadata":{"scrolled":false,"id":"kORQOo9gYNDZ"},"source":["# add code here\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OIFaYgUWYNDa"},"source":["### Standardize the features using sklearn.preprocessing \n","Why should we standardize?<br>\n","Variables that are measured at different scales do not contribute equally to the model fitting & model learned function and might end up creating a bias. Thus, to deal with this potential problem feature-wise standardized (μ=0, σ=1) is usually used prior to model fitting.<br>\n","<br>\n","Go through this link for a better understanding:<br>\n","https://towardsdatascience.com/how-and-why-to-standardize-your-data-996926c2c832"]},{"cell_type":"markdown","metadata":{"id":"EzMEGA9fYNDa"},"source":["**import StandardScaler from Sklearn and instantiate it to a variable called \"scaler\"**"]},{"cell_type":"code","metadata":{"id":"HVWU81uvYNDb"},"source":["# add code here\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HlKUjW9XYNDb"},"source":["**Fit only the features data to this scaler (leaving the TARGET CLASS column out) and then transform**<br>\n","Hint: scaler.fit() and scaler.transform()"]},{"cell_type":"code","metadata":{"id":"MCbkapp4YNDb"},"source":["# add code here\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uZTbl8UBYNDc"},"source":["**Scaler.transform() will return an array. We need to convert this into a dataframe. Do this and add the column names to the dataframe. Call this new dataframe as \"df_feat\". Call head() on this df**<br>\n","Note: The final dataframe will have the initial columns except the \"TARGET CLASS\"."]},{"cell_type":"code","metadata":{"id":"m6DnntqtYNDc"},"source":["# add code here\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vWiXgySxYNDd"},"source":["### Train/Test split"]},{"cell_type":"markdown","metadata":{"id":"xgJQPOfXYNDd"},"source":["**Set X to be equal to df_feat and set y accordingly. As you know, X contains our training features and y contains our target.**<br>\n","Hint: y can be taken directly from the initaial dataframe \"df\""]},{"cell_type":"code","metadata":{"id":"W94s-2-jYNDd"},"source":["# add code here\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5tyZdg0nYNDd"},"source":["**Import train_test_split function from scikit-learn**<br>\n","**Create X and y train and test splits in one command using a test size of 0.3 and a random seed**<br>\n","They should be called X_train, X_test, y_train, y_test"]},{"cell_type":"code","metadata":{"id":"wiNlmT2IYNDe"},"source":["# add code here\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N6tS1j4iYNDe"},"source":["### Model fit and training"]},{"cell_type":"markdown","metadata":{"id":"7A_LeaNAYNDe"},"source":["**import KNeighborsClassifier from sklearn and initialize it with neighbours = 1. Fit this on X_train and y_train**"]},{"cell_type":"code","metadata":{"id":"kaSJJTYDYNDf"},"source":["# add code here\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eAEVkt6LYNDf"},"source":["**Using this fitted model, predict on X_test. Store these predictions in variable called pred.**"]},{"cell_type":"code","metadata":{"id":"rsnjjXaMYNDf"},"source":["# add code here\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7IcCOyuOYNDf"},"source":["**Let us check how correct these predictions are.<br>\n","Print a classification report of y_test and pred**<br>\n","Hint: sklearn classification_report"]},{"cell_type":"code","metadata":{"id":"HC-20WeuYNDg"},"source":["# add code here\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"exGvX0C5YNDg"},"source":["**Print the accuracy using numpy and round it to 3 decimal places.**"]},{"cell_type":"code","metadata":{"id":"sSoOx6MiYNDg"},"source":["# add code here\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UWjjrBrbYNDh"},"source":["### Choosing optimal 'k'"]},{"cell_type":"markdown","metadata":{"id":"IT_5lBDVYNDh"},"source":["**Above, we chose n_neighbours to be equal to 1. Choosing a small value of K leads to unstable decision boundaries. <br>\n","We need to select n_neighbours by calculating the accuracy for every value of n from 1 to 60 and then choosing the one which gives the highest accuracy.**"]},{"cell_type":"code","metadata":{"id":"xPKm3inZYNDh"},"source":["# Do the same as we did above, but this time make a loop from n = 1 to n = 60 and append the accuracy\n","# for each in a list\n","\n","# add code here\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5LUl_JMUYNDi"},"source":["**Plot a graph of K value vs Accuracy**"]},{"cell_type":"code","metadata":{"id":"DvsbINxsYNDi"},"source":["# add code here\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KO4KK1WEYNDi"},"source":["**Choose the best value of n_neighbours and give a reason why and also print the accuracy**"]},{"cell_type":"code","metadata":{"id":"SWf5hh-jYNDj"},"source":["# add code here "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8gIMbzLJd8bu"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z4CBOAiOd9is"},"source":["# 3). Decision Tree Classifier"]},{"cell_type":"markdown","metadata":{"id":"UXCHg4IQewph"},"source":["<b>read the titanic_data.csv using pandas and show the dataframe</b>"]},{"cell_type":"code","metadata":{"id":"8dGi9n5meB94"},"source":["#write code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ph135_ppe2I4"},"source":["<b>Write a function which accepts a dataframe, preprocesses the data (use task 1 notebook) and returns a new dataframe. </b> <br>\n","you may need a helper function for normalizing data so feel free to define that as well"]},{"cell_type":"code","metadata":{"id":"nEgFQI3se0dn"},"source":["def titanic_preprocessing_pipeline(df):\n","  #enter preprocessing steps as done in task 1\n","  #make sure the preprocessed dataframe looks like the output in task 1\n","  #return the dataframe\n","  pass #remove this line after writing the code"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rlnz6P-xh1SA"},"source":["<b>extract the y label (survived) from the dataframe and store it in a new variable</b>"]},{"cell_type":"code","metadata":{"id":"R0WuPt4DhpOx"},"source":["#write code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NzP6YHDTiC--"},"source":["<b>remove the y_label (survived) from the dataframe</b>"]},{"cell_type":"code","metadata":{"id":"DI0KwhYHiIBT"},"source":["#write code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7ut650pSiIw1"},"source":["<b>Split the data into train and test. (do a split in the ratio 30:70)</b>"]},{"cell_type":"code","metadata":{"id":"phcn_hG7iRIN"},"source":["#write code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sqZl02RsiSbJ"},"source":["<b>Now that you have the entire preprocessed and split data, implement the decision tree algorithm from sklearn and fit it to this dataset</b> <br>\n","\n","Make sure that you play with the hyperparameters to get a good result. You can even use bagging and boosting methods like random forest or adaboost to improve your accuracy. Visualize results, try different hyperparameters by using a loop, GET CREATIVE!<br>\n","\n","Machine learning is an iteritive process. You will have to keep playing with hyperparameters and algorithms. No fixed algorithm will work on a fixed dataset.\n","\n","Take this up as a challenge. The person with the best accuracy wins the round!"]},{"cell_type":"markdown","metadata":{"id":"EVNqRQx2j6iO"},"source":["<b>Note that the accuracy on the test set will be considered and brownie points for not overfitting the model in the process</b>"]},{"cell_type":"code","metadata":{"id":"ulNAgERBjytd"},"source":["#write code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qpSDT-ZlkhRS"},"source":["<b>print the test accuracy and train accuracy here</b>"]},{"cell_type":"code","metadata":{"id":"6zUFG8T7kkJz"},"source":["#write code here"],"execution_count":null,"outputs":[]}]}